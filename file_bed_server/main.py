# file_bed_server/main.py
import base64
import os
import uuid
import time
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import logging
from apscheduler.schedulers.background import BackgroundScheduler
import json
from PIL import Image
import io

# --- åŸºç¡€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- è·¯å¾„é…ç½® ---
# å°†ä¸Šä¼ ç›®å½•å®šä½åˆ° main.py æ–‡ä»¶çš„åŒçº§ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
API_KEY = "your_secret_api_key"  # ç®€å•çš„è®¤è¯å¯†é’¥
CLEANUP_INTERVAL_MINUTES = 1 # æ¸…ç†ä»»åŠ¡è¿è¡Œé¢‘ç‡ï¼ˆåˆ†é’Ÿï¼‰
FILE_MAX_AGE_MINUTES = 10 # æ–‡ä»¶æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰

# --- å›¾ç‰‡ä¼˜åŒ–é…ç½® ---
def load_optimization_config():
    """åŠ è½½ä¼˜åŒ–é…ç½®"""
    try:
        # å‡è®¾ config.jsonc åœ¨ file_bed_server ç›®å½•çš„ä¸Šä¸€çº§
        config_path = os.path.join(os.path.dirname(BASE_DIR), 'config.jsonc')
        with open(config_path, 'r', encoding='utf-8') as f:
            # ç®€å•å¤„ç†jsoncæ³¨é‡Š
            content = '\n'.join(line for line in f if not line.strip().startswith('//'))
            config = json.loads(content)
            return config.get('image_optimization', {})
    except Exception as e:
        logger.error(f"åŠ è½½å›¾ç‰‡ä¼˜åŒ–é…ç½®å¤±è´¥: {e}", exc_info=True)
        return {'enabled': False}

OPTIMIZATION_CONFIG = load_optimization_config()
if OPTIMIZATION_CONFIG.get('enabled'):
    logger.info("å›¾ç‰‡ä¼˜åŒ–åŠŸèƒ½å·²å¯ç”¨ã€‚")

# --- æ¸…ç†å‡½æ•° ---
def cleanup_old_files():
    """éå†ä¸Šä¼ ç›®å½•å¹¶åˆ é™¤è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ–‡ä»¶ã€‚"""
    now = time.time()
    cutoff = now - (FILE_MAX_AGE_MINUTES * 60)
    
    logger.info(f"æ­£åœ¨è¿è¡Œæ¸…ç†ä»»åŠ¡ï¼Œåˆ é™¤æ—©äº {datetime.fromtimestamp(cutoff).strftime('%Y-%m-%d %H:%M:%S')} çš„æ–‡ä»¶...")
    
    deleted_count = 0
    try:
        for filename in os.listdir(UPLOAD_DIR):
            file_path = os.path.join(UPLOAD_DIR, filename)
            if os.path.isfile(file_path):
                try:
                    file_mtime = os.path.getmtime(file_path)
                    if file_mtime < cutoff:
                        os.remove(file_path)
                        logger.info(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {filename}")
                        deleted_count += 1
                except OSError as e:
                    logger.error(f"åˆ é™¤æ–‡ä»¶ '{file_path}' æ—¶å‡ºé”™: {e}")
    except Exception as e:
        logger.error(f"æ¸…ç†æ—§æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)

    if deleted_count > 0:
        logger.info(f"æ¸…ç†ä»»åŠ¡å®Œæˆï¼Œå…±åˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶ã€‚")
    else:
        logger.info("æ¸…ç†ä»»åŠ¡å®Œæˆï¼Œæ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆ é™¤çš„æ–‡ä»¶ã€‚")


# --- FastAPI ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ ---
scheduler = BackgroundScheduler(timezone="UTC")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶å¯åŠ¨åå°ä»»åŠ¡ï¼Œåœ¨å…³é—­æ—¶åœæ­¢ã€‚"""
    # å¯åŠ¨è°ƒåº¦å™¨å¹¶æ·»åŠ ä»»åŠ¡
    scheduler.add_job(cleanup_old_files, 'interval', minutes=CLEANUP_INTERVAL_MINUTES)
    scheduler.start()
    logger.info(f"åå°æ–‡ä»¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ¯ {CLEANUP_INTERVAL_MINUTES} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ã€‚")
    yield
    # å…³é—­è°ƒåº¦å™¨
    scheduler.shutdown()
    logger.info("åå°æ–‡ä»¶æ¸…ç†ä»»åŠ¡å·²åœæ­¢ã€‚")


app = FastAPI(lifespan=lifespan)

# --- ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨ ---
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)
    logger.info(f"ä¸Šä¼ ç›®å½• '{UPLOAD_DIR}' å·²åˆ›å»ºã€‚")

# --- æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ä»¥æä¾›æ–‡ä»¶è®¿é—® ---
app.mount(f"/uploads", StaticFiles(directory=UPLOAD_DIR), name="uploads")

# --- Pydantic æ¨¡å‹å®šä¹‰ ---
class UploadRequest(BaseModel):
    file_name: str
    file_data: str # æ¥æ”¶å®Œæ•´çš„ base64 data URI
    api_key: str | None = None

# --- API ç«¯ç‚¹ ---
@app.post("/upload")
async def upload_file(request: UploadRequest, http_request: Request):
    """
    æ¥æ”¶ base64 ç¼–ç çš„æ–‡ä»¶å¹¶ä¿å­˜ï¼Œè¿”å›å¯è®¿é—®çš„ URLã€‚
    """
    # ç®€å•çš„ API Key è®¤è¯
    if API_KEY and request.api_key != API_KEY:
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„ API Key")

    try:
        # 1. è§£æ base64 data URI
        header, encoded_data = request.file_data.split(',', 1)
        
        # 2. è§£ç  base64 æ•°æ®
        file_data = base64.b64decode(encoded_data)

        # 3. ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åä»¥é¿å…å†²çª
        file_extension = os.path.splitext(request.file_name)[1]
        if not file_extension:
            # å°è¯•ä» header ä¸­è·å– mime ç±»å‹æ¥çŒœæµ‹æ‰©å±•å
            import mimetypes
            mime_type = header.split(';')[0].split(':')[1]
            guessed_extension = mimetypes.guess_extension(mime_type)
            file_extension = guessed_extension if guessed_extension else '.bin'

        # å›¾ç‰‡ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if OPTIMIZATION_CONFIG.get('enabled') and file_extension.lower() in ['.jpg', '.jpeg', '.png', '.webp', '.bmp', '.gif', '.tiff']:
            try:
                img = Image.open(io.BytesIO(file_data))
                original_size = len(file_data)

                # æ­¥éª¤1: æ¸…é™¤å…ƒæ•°æ®
                if OPTIMIZATION_CONFIG.get('strip_metadata'):
                    # åˆ›å»ºä¸€ä¸ªæ²¡æœ‰exifæ•°æ®çš„æ–°å›¾åƒ
                    img_data = list(img.getdata())
                    img_clean = Image.new(img.mode, img.size)
                    img_clean.putdata(img_data)
                    img = img_clean

                # æ­¥éª¤2: è°ƒæ•´å°ºå¯¸
                max_w = OPTIMIZATION_CONFIG.get('max_width', 1920)
                max_h = OPTIMIZATION_CONFIG.get('max_height', 1080)
                if img.width > max_w or img.height > max_h:
                    img.thumbnail((max_w, max_h), Image.Resampling.LANCZOS)

                # æ­¥éª¤3: ä¼˜åŒ–ä¿å­˜
                output = io.BytesIO()
                save_kwargs = {}
                
                # ç¡®å®šè¾“å‡ºæ ¼å¼
                output_format = img.format
                if OPTIMIZATION_CONFIG.get('convert_to_webp'):
                    output_format = 'WEBP'
                    file_extension = '.webp'
                
                # å¤„ç†é€æ˜åº¦ä»¥å…¼å®¹JPEG
                if output_format == 'JPEG' and img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    background.paste(img, mask=img.split()[-1] if 'A' in img.mode else None)
                    img = background

                if output_format in ('JPEG', 'WEBP'):
                    save_kwargs['quality'] = OPTIMIZATION_CONFIG.get(f'{output_format.lower()}_quality', 85)
                
                if OPTIMIZATION_CONFIG.get('optimize_encoding'):
                    save_kwargs['optimize'] = True
                
                if output_format == 'WEBP' and OPTIMIZATION_CONFIG.get('progressive_encoding'):
                    save_kwargs['method'] = 6 # method 6 is the slowest but gives the best compression

                img.save(output, format=output_format, **save_kwargs)
                
                optimized_data = output.getvalue()
                optimized_size = len(optimized_data)
                
                logger.info(f"å›¾ç‰‡ä¼˜åŒ–: {original_size/1024:.2f}KB â†’ {optimized_size/1024:.2f}KB "
                           f"({(1-optimized_size/original_size)*100:.1f}% å‹ç¼©)")
                
                file_data = optimized_data
                
            except Exception as e:
                logger.warning(f"å›¾ç‰‡ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾: {e}", exc_info=True)

        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)

        # 4. ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(file_data)
        
        # 5. è¿”å›æˆåŠŸä¿¡æ¯å’Œå”¯ä¸€æ–‡ä»¶å
        logger.info(f"æ–‡ä»¶ '{request.file_name}' å·²æˆåŠŸä¿å­˜ä¸º '{unique_filename}'ã€‚")
        
        return JSONResponse(
            status_code=200,
            content={"success": True, "filename": unique_filename}
        )

    except (ValueError, IndexError) as e:
        logger.error(f"è§£æ base64 æ•°æ®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ base64 data URI æ ¼å¼: {e}")
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶ä¸Šä¼ æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {e}")

@app.get("/")
def read_root():
    return {"message": "LMArena Bridge æ–‡ä»¶åºŠæœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚"}

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ æ–‡ä»¶åºŠæœåŠ¡å™¨æ­£åœ¨å¯åŠ¨...")
    logger.info("   - ç›‘å¬åœ°å€: https://api.spinsnow.fun/file-bed-server")
    logger.info(f"   - ä¸Šä¼ ç«¯ç‚¹: https://api.spinsnow.fun/file-bed-server/upload")
    logger.info(f"   - æ–‡ä»¶è®¿é—®è·¯å¾„: /uploads")
    uvicorn.run(app, host="0.0.0.0", port=5180)